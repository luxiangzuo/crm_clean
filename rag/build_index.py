from dotenv import load_dotenv
load_dotenv()
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from langchain_community.vectorstores import FAISS
from utils.embedding_loader import load_embedding_model
from langchain.docstore.document import Document
from langchain.text_splitter import MarkdownHeaderTextSplitter  # ç”¨è¿™ä¸ªï¼
# from langchain.text_splitter import CharacterTextSplitter   # ä¸å†ä½¿ç”¨

def load_markdown_files(root_dir):
    all_chunks = []
    
    splitter = MarkdownHeaderTextSplitter(
        headers_to_split_on=[
            ("#", "Section"),
            ("##", "Subsection"),
            ("###", "QA")  # QAçº§åˆ«çš„é—®é¢˜ç»“æ„
        ]
    )

    for foldername, _, filenames in os.walk(root_dir):
        for filename in filenames:
            if filename.endswith(".md"):
                filepath = os.path.join(foldername, filename)
                with open(filepath, 'r', encoding='utf-8') as f:
                    text = f.read()

                metadata = {
                    "source": os.path.relpath(filepath, root_dir)
                }

                docs = splitter.split_text(text)
                print(f"ğŸ“„ æ–‡æ¡£: {metadata['source']} â¤ åˆ‡åˆ†æˆ {len(docs)} æ®µ")

                # æ·»åŠ æºæ–‡ä»¶è·¯å¾„åˆ°æ¯æ®µçš„ metadata
                for doc in docs:
                    doc.metadata["source"] = metadata["source"]
                    all_chunks.append(doc)

    print(f"\nğŸ“Š æ‰€æœ‰æ–‡æ¡£å…±åˆ‡åˆ†å‡º {len(all_chunks)} ä¸ªæ®µè½ã€‚\n")
    return all_chunks

def build_index(doc_dir="documents", index_dir="rag/joja_index"):
    print("ğŸ” æ­£åœ¨åŠ è½½å¹¶åˆ‡åˆ† Markdown æ–‡æ¡£...")
    docs = load_markdown_files(doc_dir)

    if not docs:
        raise ValueError(f"âŒ æœªæ‰¾åˆ°æœ‰æ•ˆæ–‡æ¡£ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®: {doc_dir}")

    print(f"ğŸ“š å…±åˆ‡åˆ†å‡º {len(docs)} ä¸ªæ®µè½ï¼Œå¼€å§‹ç”Ÿæˆå‘é‡...")
    embeddings = load_embedding_model("openai")  # æˆ– "gemini"
    vectordb = FAISS.from_documents(docs, embeddings)

    vectordb.save_local(index_dir)
    print(f"âœ… å‘é‡ç´¢å¼•æ„å»ºå®Œæˆï¼Œä¿å­˜åœ¨ {index_dir}")

if __name__ == "__main__":
    build_index()
