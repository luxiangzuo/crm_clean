# rag/retrieve_docs.py
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
def load_vectorstore(index_path="rag/joja_index"):
    embeddings = OpenAIEmbeddings()
    return FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)

def retrieve_docs(query, top_k=5, score_threshold=2.2, debug=True, fallback_text=None):
    db = load_vectorstore()
    results_with_score = db.similarity_search_with_score(query, k=top_k)

    filtered = []
    for i, (doc, score) in enumerate(results_with_score):
        if score <= score_threshold:
            filtered.append(doc)
        else:
            if debug:
                print(f"âŒ ä¸¢å¼ƒä½Žç›¸å…³æ®µè½ï¼ˆscore={score:.4f}ï¼‰: {doc.page_content[:50]}...")

    if not filtered:
        print("âš ï¸ RAG æ²¡æœ‰å¬å›žä»»ä½•æ–‡æ¡£ï¼æ¨¡åž‹å³å°†è‡ªç”±å‘æŒ¥ï¼ðŸš¨")
        if fallback_text:
            print("ðŸš¨ ä½¿ç”¨ fallback å†…å®¹æ›¿ä»£æ–‡æ¡£ç‰‡æ®µã€‚")
            return fallback_text

    if debug:
        print(f"\nâœ… æœ€ç»ˆä¿ç•™æ®µè½æ•°ï¼š{len(filtered)}")
        print("\nðŸ“š æœ€ç»ˆå¬å›žæ®µè½å†…å®¹å¦‚ä¸‹ï¼š")
        for i, doc in enumerate(filtered):
            print(f"\n[æ®µè½ {i+1}] æ¥è‡ª {doc.metadata.get('source', '')}")
            print(doc.page_content)
            print("---")

    return "\n\n".join([f"[{i+1}] {doc.page_content}" for i, doc in enumerate(filtered)])
